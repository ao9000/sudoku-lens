{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert PyTorch model to TorchScript for Android",
   "id": "b396555390e498e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T10:52:02.985202Z",
     "start_time": "2025-06-13T10:52:02.852319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from helper_functions_pt import MNISTClassifier\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = MNISTClassifier().to(device)\n",
    "state_dict = torch.load(\"models/pt_cnn/ft_model_epoch12.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Trace the model and save as TorchScript\n",
    "traced_script_module = torch.jit.script(model)\n",
    "\n",
    "# This will result in minor differences in the model compared to the original PyTorch model\n",
    "traced_script_module = optimize_for_mobile(traced_script_module)\n",
    "\n",
    "output_path = \"models/pt_cnn/sudoku_digit_classifier_android.ptl\"\n",
    "traced_script_module._save_for_lite_interpreter(output_path)\n",
    "print(f\"Saved TorchScript model to {output_path}\")"
   ],
   "id": "d89ce10e7056b017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TorchScript model to models/pt_cnn/sudoku_digit_classifier_android.ptl\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare predictions from the original and TorchScript models, should be equal",
   "id": "19e6b57b4c8698"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T14:31:14.631470Z",
     "start_time": "2025-06-12T14:31:14.476625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from digits_classifier import sudoku_cells_reduce_noise\n",
    "import cv2\n",
    "from helper_functions_pt import MNISTClassifier, get_mnist_transform\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ[\"XNNPACK_DISABLE\"] = \"1\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "# Path to your mobile‐optimized TorchScript\n",
    "ptl_path = \"models/pt_cnn/sudoku_digit_classifier_android.ptl\"\n",
    "jitted_model = torch.jit.load(ptl_path, map_location=device)\n",
    "jitted_model.eval()\n",
    "\n",
    "# Define testing image filename\n",
    "test_img = \"test/1/1.jpg.png\"\n",
    "\n",
    "# Load testing image\n",
    "digit = cv2.imread(test_img, cv2.IMREAD_GRAYSCALE)\n",
    "digit_inv = cv2.adaptiveThreshold(digit, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 27, 11)\n",
    "denoised_digit = sudoku_cells_reduce_noise(digit_inv)\n",
    "if denoised_digit is not None:\n",
    "    digit = Image.fromarray(denoised_digit)\n",
    "    # Reshape to fit model input, [1,28,28]\n",
    "    digit_tensor = get_mnist_transform()(digit)\n",
    "    # Add batch dim, send to device\n",
    "    digit_tensor = digit_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    jitted_logits = jitted_model(digit_tensor)\n",
    "\n",
    "    arg_max = torch.argmax(jitted_logits, dim=1)+1\n",
    "    print(f\"Predicted digit: {arg_max.item()}\")\n"
   ],
   "id": "9fabfe01aea8b26d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T14:31:33.544958Z",
     "start_time": "2025-06-12T14:31:33.508670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path\n",
    "path = \"models/pt_cnn/ft_model_epoch10.pth\"\n",
    "device = \"cpu\"\n",
    "model = MNISTClassifier().to(device)\n",
    "state_dict = torch.load(path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Define testing image filename\n",
    "test_img = \"test/1/1.jpg.png\"\n",
    "\n",
    "# Load testing image\n",
    "digit = cv2.imread(test_img, cv2.IMREAD_GRAYSCALE)\n",
    "digit_inv = cv2.adaptiveThreshold(digit, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 27, 11)\n",
    "denoised_digit = sudoku_cells_reduce_noise(digit_inv)\n",
    "if denoised_digit is not None:\n",
    "    digit = Image.fromarray(denoised_digit)\n",
    "    # Reshape to fit model input, [1,28,28]\n",
    "    digit_tensor = get_mnist_transform()(digit)\n",
    "    # Add batch dim, send to device\n",
    "    digit_tensor = digit_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(digit_tensor)\n",
    "        prediction = torch.argmax(logits, dim=1).item()+1\n",
    "        print(f\"Predicted digit: {prediction}\")\n"
   ],
   "id": "ec3b370aad8677b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T14:31:37.005375Z",
     "start_time": "2025-06-12T14:31:36.974900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Absolute match\n",
    "if not torch.equal(logits, jitted_logits):\n",
    "    diff = (logits - jitted_logits).abs().max().item()\n",
    "    raise AssertionError(f\"logits differ! max absolute difference = {diff}\")\n",
    "print(\"Exact match!\")\n",
    "\n",
    "# optimize_for_mobile will fail this check"
   ],
   "id": "52c2f299e5b8942c",
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "logits differ! max absolute difference = 7.62939453125e-06",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mequal(logits, jitted_logits):\n\u001B[0;32m      3\u001B[0m     diff \u001B[38;5;241m=\u001B[39m (logits \u001B[38;5;241m-\u001B[39m jitted_logits)\u001B[38;5;241m.\u001B[39mabs()\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogits differ! max absolute difference = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdiff\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExact match!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAssertionError\u001B[0m: logits differ! max absolute difference = 7.62939453125e-06"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T14:31:38.574474Z",
     "start_time": "2025-06-12T14:31:38.555233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tiny floating‐point discrepancies\n",
    "if not torch.allclose(logits, jitted_logits, rtol=1e-5, atol=1e-6):\n",
    "    diff = (logits - jitted_logits).abs().max().item()\n",
    "    raise AssertionError(f\"logits not allclose! max absolute difference = {diff}\")\n",
    "print(\"Allclose match!\")"
   ],
   "id": "5d61b10c20291343",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allclose match!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dcecf0730603b2a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
