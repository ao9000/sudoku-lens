{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Convert PyTorch model to TorchScript for Android",
   "id": "b396555390e498e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:51:00.926851Z",
     "start_time": "2025-06-06T11:50:57.075240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from helper_functions_pt import MNISTClassifier\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model = MNISTClassifier().to(device)\n",
    "state_dict = torch.load(\"models/pt_cnn/ft_model_epoch15.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Trace the model and save as TorchScript\n",
    "traced_script_module = torch.jit.script(model)\n",
    "\n",
    "# This will result in minor differences in the model compared to the original PyTorch model\n",
    "traced_script_module = optimize_for_mobile(traced_script_module)\n",
    "\n",
    "output_path = \"models/pt_cnn/ft_model_epoch15_android.ptl\"\n",
    "traced_script_module._save_for_lite_interpreter(output_path)\n",
    "print(f\"Saved TorchScript model to {output_path}\")"
   ],
   "id": "d89ce10e7056b017",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TorchScript model to models/pt_cnn/ft_model_epoch15_android.ptl\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Compare predictions from the original and TorchScript models, should be equal",
   "id": "19e6b57b4c8698"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:51:01.874220Z",
     "start_time": "2025-06-06T11:51:01.785016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from digits_classifier import sudoku_cells_reduce_noise\n",
    "import cv2\n",
    "from helper_functions_pt import MNISTClassifier, get_mnist_transform\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ[\"XNNPACK_DISABLE\"] = \"1\"\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "# Path to your mobile‐optimized TorchScript\n",
    "ptl_path = \"models/pt_cnn/ft_model_epoch15_android.ptl\"\n",
    "jitted_model = torch.jit.load(ptl_path, map_location=device)\n",
    "jitted_model.eval()\n",
    "\n",
    "# Define testing image filename\n",
    "test_img = \"test/1/1.jpg.png\"\n",
    "\n",
    "# Load testing image\n",
    "digit = cv2.imread(test_img, cv2.IMREAD_GRAYSCALE)\n",
    "digit_inv = cv2.adaptiveThreshold(digit, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 27, 11)\n",
    "denoised_digit = sudoku_cells_reduce_noise(digit_inv)\n",
    "if denoised_digit is not None:\n",
    "    digit = Image.fromarray(denoised_digit)\n",
    "    # Reshape to fit model input, [1,28,28]\n",
    "    digit_tensor = get_mnist_transform()(digit)\n",
    "    # Add batch dim, send to device\n",
    "    digit_tensor = digit_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    jitted_logits = jitted_model(digit_tensor)\n",
    "\n",
    "    arg_max = torch.argmax(jitted_logits, dim=1)+1\n",
    "    print(f\"Predicted digit: {arg_max.item()}\")\n"
   ],
   "id": "9fabfe01aea8b26d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "code/__torch__/torch/nn/functional.py:93: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:51:02.058454Z",
     "start_time": "2025-06-06T11:51:02.033198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path\n",
    "path = \"models/pt_cnn/ft_model_epoch15.pth\"\n",
    "device = \"cpu\"\n",
    "model = MNISTClassifier().to(device)\n",
    "state_dict = torch.load(path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Define testing image filename\n",
    "test_img = \"test/1/1.jpg.png\"\n",
    "\n",
    "# Load testing image\n",
    "digit = cv2.imread(test_img, cv2.IMREAD_GRAYSCALE)\n",
    "digit_inv = cv2.adaptiveThreshold(digit, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 27, 11)\n",
    "denoised_digit = sudoku_cells_reduce_noise(digit_inv)\n",
    "if denoised_digit is not None:\n",
    "    digit = Image.fromarray(denoised_digit)\n",
    "    # Reshape to fit model input, [1,28,28]\n",
    "    digit_tensor = get_mnist_transform()(digit)\n",
    "    # Add batch dim, send to device\n",
    "    digit_tensor = digit_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(digit_tensor)\n",
    "        prediction = torch.argmax(logits, dim=1).item()+1\n",
    "        print(f\"Predicted digit: {prediction}\")\n"
   ],
   "id": "ec3b370aad8677b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aozy\\Desktop\\sudoku-lens\\digits_classifier\\helper_functions_pt.py:65: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:51:04.827608Z",
     "start_time": "2025-06-06T11:51:04.815533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Absolute match\n",
    "if not torch.equal(logits, jitted_logits):\n",
    "    diff = (logits - jitted_logits).abs().max().item()\n",
    "    raise AssertionError(f\"logits differ! max absolute difference = {diff}\")\n",
    "print(\"Exact match!\")\n",
    "\n",
    "# optimize_for_mobile will fail this check"
   ],
   "id": "52c2f299e5b8942c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact match!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T11:51:06.922020Z",
     "start_time": "2025-06-06T11:51:06.910904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tiny floating‐point discrepancies\n",
    "if not torch.allclose(logits, jitted_logits, rtol=1e-5, atol=1e-6):\n",
    "    diff = (logits - jitted_logits).abs().max().item()\n",
    "    raise AssertionError(f\"logits not allclose! max absolute difference = {diff}\")\n",
    "print(\"Allclose match!\")"
   ],
   "id": "5d61b10c20291343",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allclose match!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dcecf0730603b2a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
